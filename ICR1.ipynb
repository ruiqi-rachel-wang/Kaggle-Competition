{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install tabpfn --no-index --find-links=file:///kaggle/input/pip-packages-icr/pip-packages\n!mkdir -p /opt/conda/lib/python3.10/site-packages/tabpfn/models_diff\n!cp /kaggle/input/pip-packages-icr/pip-packages/prior_diff_real_checkpoint_n_0_epoch_100.cpkt /opt/conda/lib/python3.10/site-packages/tabpfn/models_diff/","metadata":{"execution":{"iopub.status.busy":"2023-06-27T05:54:15.143705Z","iopub.execute_input":"2023-06-27T05:54:15.144383Z","iopub.status.idle":"2023-06-27T05:54:33.194395Z","shell.execute_reply.started":"2023-06-27T05:54:15.144346Z","shell.execute_reply":"2023-06-27T05:54:33.19293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder,normalize\nfrom sklearn.ensemble import GradientBoostingClassifier,RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.impute import SimpleImputer\nimport imblearn\nfrom imblearn.over_sampling import RandomOverSampler\nfrom imblearn.under_sampling import RandomUnderSampler\nimport xgboost\nimport inspect\nfrom collections import defaultdict\nfrom tabpfn import TabPFNClassifier\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-27T05:54:33.197495Z","iopub.execute_input":"2023-06-27T05:54:33.198137Z","iopub.status.idle":"2023-06-27T05:54:40.630786Z","shell.execute_reply.started":"2023-06-27T05:54:33.198095Z","shell.execute_reply":"2023-06-27T05:54:40.629709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/train.csv')\ntest = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/test.csv')\nsample = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/sample_submission.csv')\ngreeks = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/greeks.csv')","metadata":{"execution":{"iopub.status.busy":"2023-06-27T05:54:40.643155Z","iopub.execute_input":"2023-06-27T05:54:40.643815Z","iopub.status.idle":"2023-06-27T05:54:40.704343Z","shell.execute_reply.started":"2023-06-27T05:54:40.64378Z","shell.execute_reply":"2023-06-27T05:54:40.703425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"first_category = train.EJ.unique()[0]\ntrain.EJ = train.EJ.eq(first_category).astype('int')\ntest.EJ = test.EJ.eq(first_category).astype('int')","metadata":{"execution":{"iopub.status.busy":"2023-06-27T05:54:40.714371Z","iopub.execute_input":"2023-06-27T05:54:40.715222Z","iopub.status.idle":"2023-06-27T05:54:40.734724Z","shell.execute_reply.started":"2023-06-27T05:54:40.715188Z","shell.execute_reply":"2023-06-27T05:54:40.733784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def random_under_sampler(df):\n    # Calculate the number of samples for each label. \n    neg, pos = np.bincount(df['Class'])\n\n    # Choose the samples with class label `1`.\n    one_df = df.loc[df['Class'] == 1] \n    # Choose the samples with class label `0`.\n    zero_df = df.loc[df['Class'] == 0]\n    # Select `pos` number of negative samples.\n    # This makes sure that we have equal number of samples for each label.\n    zero_df = zero_df.sample(n=pos)\n\n    # Join both label dataframes.\n    undersampled_df = pd.concat([zero_df, one_df])\n\n    # Shuffle the data and return\n    return undersampled_df.sample(frac = 1)","metadata":{"execution":{"iopub.status.busy":"2023-06-27T05:54:40.736512Z","iopub.execute_input":"2023-06-27T05:54:40.736917Z","iopub.status.idle":"2023-06-27T05:54:40.744779Z","shell.execute_reply.started":"2023-06-27T05:54:40.736887Z","shell.execute_reply":"2023-06-27T05:54:40.743657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_good = random_under_sampler(train)\ntrain_good.shape\npredictor_columns = [n for n in train.columns if n != 'Class' and n != 'Id']\nx = train[predictor_columns]\ny = train['Class']","metadata":{"execution":{"iopub.status.busy":"2023-06-27T05:54:40.746447Z","iopub.execute_input":"2023-06-27T05:54:40.74684Z","iopub.status.idle":"2023-06-27T05:54:40.768261Z","shell.execute_reply.started":"2023-06-27T05:54:40.746808Z","shell.execute_reply":"2023-06-27T05:54:40.767153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import KFold as KF, GridSearchCV\ncv_outer = KF(n_splits = 10, shuffle=True, random_state=42)\ncv_inner = KF(n_splits = 5, shuffle=True, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-06-27T05:54:40.805563Z","iopub.execute_input":"2023-06-27T05:54:40.806658Z","iopub.status.idle":"2023-06-27T05:54:40.815601Z","shell.execute_reply.started":"2023-06-27T05:54:40.806623Z","shell.execute_reply":"2023-06-27T05:54:40.814457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def balanced_log_loss(y_true, y_pred):\n    N_0 = np.sum(1 - y_true)\n    N_1 = np.sum(y_true)\n    # calculate the weights for each class to balance classes\n    w_0 = 1 / N_0\n    w_1 = 1 / N_1\n    # calculate the predicted probabilities for each class\n    p_1 = np.clip(y_pred, 1e-15, 1 - 1e-15)\n    p_0 = 1 - p_1\n    # calculate the summed log loss for each class\n    log_loss_0 = -np.sum((1 - y_true) * np.log(p_0))\n    log_loss_1 = -np.sum(y_true * np.log(p_1))\n    # calculate the weighted summed logarithmic loss\n    # (factgor of 2 included to give same result as LL with balanced input)\n    balanced_log_loss = 2*(w_0 * log_loss_0 + w_1 * log_loss_1) / (w_0 + w_1)\n    # return the average log loss\n    return balanced_log_loss/(N_0+N_1)","metadata":{"execution":{"iopub.status.busy":"2023-06-27T05:54:40.817297Z","iopub.execute_input":"2023-06-27T05:54:40.818055Z","iopub.status.idle":"2023-06-27T05:54:40.828691Z","shell.execute_reply.started":"2023-06-27T05:54:40.818019Z","shell.execute_reply":"2023-06-27T05:54:40.82731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Ensemble():\n    def __init__(self):\n        self.imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n\n        self.classifiers =[xgboost.XGBClassifier(n_estimators=100,max_depth=3,learning_rate=0.2,subsample=0.9,colsample_bytree=0.85),\n                           xgboost.XGBClassifier(),\n                           TabPFNClassifier(N_ensemble_configurations=12),\n                          TabPFNClassifier(N_ensemble_configurations=12)]\n    \n    def fit(self,X,y):\n        y = y.values\n        unique_classes, y = np.unique(y, return_inverse=True)\n        self.classes_ = unique_classes\n        first_category = X.EJ.unique()[0]\n        X.EJ = X.EJ.eq(first_category).astype('int')\n        X = self.imputer.fit_transform(X)\n#         X = normalize(X,axis=0)\n        for classifier in self.classifiers:\n            if classifier==self.classifiers[2] or classifier==self.classifiers[3]:\n                classifier.fit(X,y,overwrite_warning =True)\n            else :\n                classifier.fit(X, y)\n     \n    def predict_proba(self, x):\n        x = self.imputer.transform(x)\n#         x = normalize(x,axis=0)\n        probabilities = np.stack([classifier.predict_proba(x) for classifier in self.classifiers])\n        averaged_probabilities = np.mean(probabilities, axis=0)\n        class_0_est_instances = averaged_probabilities[:, 0].sum()\n        others_est_instances = averaged_probabilities[:, 1:].sum()\n        new_probabilities = averaged_probabilities * np.array([[1/(class_0_est_instances if i==0 else others_est_instances) for i in range(averaged_probabilities.shape[1])]])\n        return new_probabilities / np.sum(new_probabilities, axis=1, keepdims=1) ","metadata":{"execution":{"iopub.status.busy":"2023-06-27T05:54:40.830718Z","iopub.execute_input":"2023-06-27T05:54:40.83122Z","iopub.status.idle":"2023-06-27T05:54:40.850166Z","shell.execute_reply.started":"2023-06-27T05:54:40.831176Z","shell.execute_reply":"2023-06-27T05:54:40.848897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm.notebook import tqdm","metadata":{"execution":{"iopub.status.busy":"2023-06-27T05:54:40.852081Z","iopub.execute_input":"2023-06-27T05:54:40.853058Z","iopub.status.idle":"2023-06-27T05:54:40.976597Z","shell.execute_reply.started":"2023-06-27T05:54:40.85302Z","shell.execute_reply":"2023-06-27T05:54:40.975721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def training(model, x,y,y_meta):\n    outer_results = list()\n    best_loss = np.inf\n    split = 0\n    splits = 5\n    for train_idx,val_idx in tqdm(cv_inner.split(x), total = splits):\n        split+=1\n        x_train, x_val = x.iloc[train_idx],x.iloc[val_idx]\n        y_train, y_val = y_meta.iloc[train_idx], y.iloc[val_idx]\n                \n        model.fit(x_train, y_train)\n        y_pred = model.predict_proba(x_val)\n        probabilities = np.concatenate((y_pred[:,:1], np.sum(y_pred[:,1:], 1, keepdims=True)), axis=1)\n        p0 = probabilities[:,:1]\n        p0[p0 > 0.86] = 1\n        p0[p0 < 0.14] = 0\n        y_p = np.empty((y_pred.shape[0],))\n        for i in range(y_pred.shape[0]):\n            if p0[i]>=0.5:\n                y_p[i]= False\n            else :\n                y_p[i]=True\n        y_p = y_p.astype(int)\n        loss = balanced_log_loss(y_val,y_p)\n\n        if loss<best_loss:\n            best_model = model\n            best_loss = loss\n            print('best_model_saved')\n        outer_results.append(loss)\n        print('>val_loss=%.5f, split = %.1f' % (loss,split))\n    print('LOSS: %.5f' % (np.mean(outer_results)))\n    return best_model\n    ","metadata":{"execution":{"iopub.status.busy":"2023-06-27T05:54:40.978261Z","iopub.execute_input":"2023-06-27T05:54:40.978615Z","iopub.status.idle":"2023-06-27T05:54:40.989698Z","shell.execute_reply.started":"2023-06-27T05:54:40.978583Z","shell.execute_reply":"2023-06-27T05:54:40.988418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datetime import datetime\ntimes = greeks.Epsilon.copy()\ntimes[greeks.Epsilon != 'Unknown'] = greeks.Epsilon[greeks.Epsilon != 'Unknown'].map(lambda x: datetime.strptime(x,'%m/%d/%Y').toordinal())\ntimes[greeks.Epsilon == 'Unknown'] = np.nan","metadata":{"execution":{"iopub.status.busy":"2023-06-27T05:54:40.993518Z","iopub.execute_input":"2023-06-27T05:54:40.994585Z","iopub.status.idle":"2023-06-27T05:54:41.023075Z","shell.execute_reply.started":"2023-06-27T05:54:40.994548Z","shell.execute_reply":"2023-06-27T05:54:41.022205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_pred_and_time = pd.concat((train, times), axis=1)\ntest_predictors = test[predictor_columns]\nfirst_category = test_predictors.EJ.unique()[0]\ntest_predictors.EJ = test_predictors.EJ.eq(first_category).astype('int')\ntest_pred_and_time = np.concatenate((test_predictors, np.zeros((len(test_predictors), 1)) + train_pred_and_time.Epsilon.max() + 1), axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-06-27T05:54:41.024537Z","iopub.execute_input":"2023-06-27T05:54:41.024862Z","iopub.status.idle":"2023-06-27T05:54:41.035248Z","shell.execute_reply.started":"2023-06-27T05:54:41.024833Z","shell.execute_reply":"2023-06-27T05:54:41.034037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ros = RandomOverSampler(random_state=42)\n\ntrain_ros, y_ros = ros.fit_resample(train_pred_and_time, greeks.Alpha)\nprint('Original dataset shape')\nprint(greeks.Alpha.value_counts())\nprint('Resample dataset shape')\nprint( y_ros.value_counts())","metadata":{"execution":{"iopub.status.busy":"2023-06-27T05:54:41.037073Z","iopub.execute_input":"2023-06-27T05:54:41.037772Z","iopub.status.idle":"2023-06-27T05:54:41.091821Z","shell.execute_reply.started":"2023-06-27T05:54:41.037737Z","shell.execute_reply":"2023-06-27T05:54:41.090128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_ros = train_ros.drop(['Class', 'Id'],axis=1)\ny_ = train_ros.Class\nyt = Ensemble()\nm = training(yt,x_ros,y_,y_ros)\ny_.value_counts()/y_.shape[0]","metadata":{"execution":{"iopub.status.busy":"2023-06-27T05:54:41.093464Z","iopub.execute_input":"2023-06-27T05:54:41.093821Z","iopub.status.idle":"2023-06-27T05:54:41.101838Z","shell.execute_reply.started":"2023-06-27T05:54:41.093789Z","shell.execute_reply":"2023-06-27T05:54:41.100912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = m.predict_proba(test_pred_and_time)\nprobabilities = np.concatenate((y_pred[:,:1], np.sum(y_pred[:,1:], 1, keepdims=True)), axis=1)\np0 = probabilities[:,:1]\np0[p0 > 0.62] = 1\np0[p0 < 0.26] = 0","metadata":{"execution":{"iopub.status.busy":"2023-06-27T06:25:56.775753Z","iopub.execute_input":"2023-06-27T06:25:56.776504Z","iopub.status.idle":"2023-06-27T06:31:02.257529Z","shell.execute_reply.started":"2023-06-27T06:25:56.776451Z","shell.execute_reply":"2023-06-27T06:31:02.25644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame(test[\"Id\"], columns=[\"Id\"])\nsubmission[\"class_0\"] = p0\nsubmission[\"class_1\"] = 1 - p0\nsubmission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-06-27T06:31:02.259454Z","iopub.execute_input":"2023-06-27T06:31:02.259874Z","iopub.status.idle":"2023-06-27T06:31:02.276768Z","shell.execute_reply.started":"2023-06-27T06:31:02.259838Z","shell.execute_reply":"2023-06-27T06:31:02.275412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df = pd.read_csv('submission.csv')\nsubmission_df","metadata":{"execution":{"iopub.status.busy":"2023-06-27T06:31:02.278459Z","iopub.execute_input":"2023-06-27T06:31:02.278919Z","iopub.status.idle":"2023-06-27T06:31:02.29962Z","shell.execute_reply.started":"2023-06-27T06:31:02.278884Z","shell.execute_reply":"2023-06-27T06:31:02.298567Z"},"trusted":true},"execution_count":null,"outputs":[]}]}